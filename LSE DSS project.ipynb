{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Collect-S&amp;P-500-Companies\" data-toc-modified-id=\"Collect-S&amp;P-500-Companies-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Collect S&amp;P 500 Companies</a></span></li><li><span><a href=\"#Example-code\" data-toc-modified-id=\"Example-code-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Example code</a></span></li><li><span><a href=\"#Stock-Prices\" data-toc-modified-id=\"Stock-Prices-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Stock Prices</a></span></li><li><span><a href=\"#Calculate-Correlation\" data-toc-modified-id=\"Calculate-Correlation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Calculate Correlation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:30:59.804887Z",
     "start_time": "2021-02-13T02:30:59.297351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect S&P 500 Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:31:00.240968Z",
     "start_time": "2021-02-13T02:30:59.805895Z"
    }
   },
   "outputs": [],
   "source": [
    "table = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "sandp_df = table[0]\n",
    "\n",
    "#sandp_df.to_csv('data/S&P500-Info.csv')\n",
    "#sandp_df.to_csv(\"data/S&P500-Symbols.csv\", columns=['Symbol'])\n",
    "\n",
    "#https://medium.com/wealthy-bytes/5-lines-of-python-to-automate-getting-the-s-p-500-95a632e5e567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:31:00.254870Z",
     "start_time": "2021-02-13T02:31:00.242900Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>SEC filings</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date first added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>St. Paul, Minnesota</td>\n",
       "      <td>1976-08-09</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1964-03-31</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABMD</td>\n",
       "      <td>Abiomed</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Danvers, Massachusetts</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>815094</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>reports</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol             Security SEC filings             GICS Sector  \\\n",
       "0    MMM           3M Company     reports             Industrials   \n",
       "1    ABT  Abbott Laboratories     reports             Health Care   \n",
       "2   ABBV          AbbVie Inc.     reports             Health Care   \n",
       "3   ABMD              Abiomed     reports             Health Care   \n",
       "4    ACN            Accenture     reports  Information Technology   \n",
       "\n",
       "                GICS Sub-Industry    Headquarters Location Date first added  \\\n",
       "0        Industrial Conglomerates      St. Paul, Minnesota       1976-08-09   \n",
       "1           Health Care Equipment  North Chicago, Illinois       1964-03-31   \n",
       "2                 Pharmaceuticals  North Chicago, Illinois       2012-12-31   \n",
       "3           Health Care Equipment   Danvers, Massachusetts       2018-05-31   \n",
       "4  IT Consulting & Other Services          Dublin, Ireland       2011-07-06   \n",
       "\n",
       "       CIK      Founded  \n",
       "0    66740         1902  \n",
       "1     1800         1888  \n",
       "2  1551152  2013 (1888)  \n",
       "3   815094         1981  \n",
       "4  1467373         1989  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandp_df.head(5)\n",
    "# so the symbol is the same as the corresponding stock ticker. \n",
    "# It will be used for parsing news results that reference the company that made the headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example code\n",
    "\n",
    "Taken from https://towardsdatascience.com/sentiment-analysis-of-stocks-from-financial-news-using-python-82ebdcefb638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:34:22.676103Z",
     "start_time": "2021-02-13T02:32:07.975282Z"
    }
   },
   "outputs": [],
   "source": [
    "finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
    "\n",
    "news_tables = {}\n",
    "tickers = sandp_df['Symbol']\n",
    "\n",
    "for ticker in tickers:\n",
    "    url = finwiz_url + ticker\n",
    "    req = Request(url=url, headers={'user-agent': 'my-app/0.0.1'}) \n",
    "    try:\n",
    "        response = urlopen(req)   \n",
    "        html = BeautifulSoup(response)  # Read the contents of the file into 'html'\n",
    "        news_table = html.find(id='news-table') # Find 'news-table' in the Soup and load it into 'news_table'\n",
    "        news_tables[ticker] = news_table # Add the table to our dictionary\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:34:38.201871Z",
     "start_time": "2021-02-13T02:34:34.857909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>headline</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Feb-12-21</td>\n",
       "      <td>05:12PM</td>\n",
       "      <td>First Eagle Investment's Top 4th-Quarter Trades</td>\n",
       "      <td>GuruFocus.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Feb-12-21</td>\n",
       "      <td>10:10AM</td>\n",
       "      <td>Why 3M Is a Retiree's Dream Stock</td>\n",
       "      <td>Motley Fool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Feb-12-21</td>\n",
       "      <td>07:45AM</td>\n",
       "      <td>3 Top Value Stocks to Buy Right Now</td>\n",
       "      <td>Motley Fool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Feb-10-21</td>\n",
       "      <td>06:00AM</td>\n",
       "      <td>How a $1.9B Bond Fund Finds Opportunity in Mar...</td>\n",
       "      <td>Barrons.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Feb-09-21</td>\n",
       "      <td>02:35PM</td>\n",
       "      <td>3M Announces Upcoming Investor Events</td>\n",
       "      <td>PR Newswire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       date     time  \\\n",
       "0    MMM  Feb-12-21  05:12PM   \n",
       "1    MMM  Feb-12-21  10:10AM   \n",
       "2    MMM  Feb-12-21  07:45AM   \n",
       "3    MMM  Feb-10-21  06:00AM   \n",
       "4    MMM  Feb-09-21  02:35PM   \n",
       "\n",
       "                                            headline            news  \n",
       "0    First Eagle Investment's Top 4th-Quarter Trades   GuruFocus.com  \n",
       "1                  Why 3M Is a Retiree's Dream Stock     Motley Fool  \n",
       "2                3 Top Value Stocks to Buy Right Now     Motley Fool  \n",
       "3  How a $1.9B Bond Fund Finds Opportunity in Mar...     Barrons.com  \n",
       "4              3M Announces Upcoming Investor Events     PR Newswire  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_news = []\n",
    "\n",
    "# Iterate through the news\n",
    "for file_name, news_table in news_tables.items():\n",
    "    # Iterate through all tr tags in 'news_table'\n",
    "    for x in news_table.findAll('tr'):\n",
    "        # read the text from each tr tag into text\n",
    "        # get text from a only\n",
    "        text = x.a.get_text() \n",
    "        # splite text in the td tag into a list \n",
    "        date_scrape = x.td.text.split()\n",
    "        \n",
    "        # get news media company\n",
    "        news = x.span.get_text()\n",
    "        \n",
    "        # if the length of 'date_scrape' is 1, load 'time' as the only element\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "            \n",
    "        # else load 'date' as the 1st element and 'time' as the second    \n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "            \n",
    "        # Extract the ticker from the file name, get the string up to the 1st '_'  \n",
    "        ticker = file_name.split('_')[0]\n",
    "        \n",
    "        # Append ticker, date, time and headline as a list to the 'parsed_news' list\n",
    "        parsed_news.append([ticker, date, time, text, news])\n",
    "        \n",
    "# Set column names\n",
    "columns = ['ticker', 'date', 'time', 'headline', 'news']\n",
    "\n",
    "# Convert the parsed_news list into a DataFrame called 'parsed_and_scored_news'\n",
    "parsed_news_updated = pd.DataFrame(parsed_news, columns=columns)\n",
    "parsed_news_updated.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:34:48.450433Z",
     "start_time": "2021-02-13T02:34:41.894994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>headline</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Feb-12-21</td>\n",
       "      <td>05:12PM</td>\n",
       "      <td>First Eagle Investments Top 4thQuarter Trades</td>\n",
       "      <td>GuruFocus.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Feb-12-21</td>\n",
       "      <td>10:10AM</td>\n",
       "      <td>Why 3M Is Retirees Dream Stock</td>\n",
       "      <td>Motley Fool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Feb-12-21</td>\n",
       "      <td>07:45AM</td>\n",
       "      <td>3 Top Value Stocks Buy Right Now</td>\n",
       "      <td>Motley Fool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Feb-10-21</td>\n",
       "      <td>06:00AM</td>\n",
       "      <td>How 19B Bond Fund Finds Opportunity Market Tur...</td>\n",
       "      <td>Barrons.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Feb-09-21</td>\n",
       "      <td>02:35PM</td>\n",
       "      <td>3M Announces Upcoming Investor Events</td>\n",
       "      <td>PR Newswire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       date     time  \\\n",
       "0    MMM  Feb-12-21  05:12PM   \n",
       "1    MMM  Feb-12-21  10:10AM   \n",
       "2    MMM  Feb-12-21  07:45AM   \n",
       "3    MMM  Feb-10-21  06:00AM   \n",
       "4    MMM  Feb-09-21  02:35PM   \n",
       "\n",
       "                                            headline            news  \n",
       "0      First Eagle Investments Top 4thQuarter Trades   GuruFocus.com  \n",
       "1                     Why 3M Is Retirees Dream Stock     Motley Fool  \n",
       "2                   3 Top Value Stocks Buy Right Now     Motley Fool  \n",
       "3  How 19B Bond Fund Finds Opportunity Market Tur...     Barrons.com  \n",
       "4              3M Announces Upcoming Investor Events     PR Newswire  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to tokenize each words within the headlines to improve the sentiment score.\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def regex(x):\n",
    "    special_chars_p = \"[.®'&$’\\\"\\-()#@!?/:]\"\n",
    "    s1 = re.sub(special_chars_p, '', x)  \n",
    "    return(s1)\n",
    "\n",
    "parsed_news_updated['headline'] = parsed_news_updated['headline'].apply(regex)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.lower().split()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "parsed_news_updated_stem = parsed_news_updated.copy()\n",
    "parsed_news_updated_stem['headline'] = parsed_news_updated_stem['headline'].apply(stem_sentences)\n",
    "\n",
    "stop=stopwords.words('english')\n",
    "\n",
    "parsed_news_updated['headline'].apply(lambda x: [item for item in x if item not in stop])\n",
    "parsed_news_updated_stem['headline'].apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "parsed_news_updated['headline'] = parsed_news_updated['headline'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) \n",
    "parsed_news_updated_stem['headline'] = parsed_news_updated_stem['headline'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) \n",
    "parsed_news_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:34:56.695664Z",
     "start_time": "2021-02-13T02:34:50.966410Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>headline</th>\n",
       "      <th>news</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>05:12PM</td>\n",
       "      <td>First Eagle Investments Top 4thQuarter Trades</td>\n",
       "      <td>GuruFocus.com</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>10:10AM</td>\n",
       "      <td>Why 3M Is Retirees Dream Stock</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>07:45AM</td>\n",
       "      <td>3 Top Value Stocks Buy Right Now</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>06:00AM</td>\n",
       "      <td>How 19B Bond Fund Finds Opportunity Market Tur...</td>\n",
       "      <td>Barrons.com</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>02:35PM</td>\n",
       "      <td>3M Announces Upcoming Investor Events</td>\n",
       "      <td>PR Newswire</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>11:07AM</td>\n",
       "      <td>New 3M Polisher ST reduces number biopharma ma...</td>\n",
       "      <td>PR Newswire</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>11:07AM</td>\n",
       "      <td>New 3M Polisher ST reduces number biopharma ma...</td>\n",
       "      <td>CNW Group</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>10:30AM</td>\n",
       "      <td>3 Stocks Buy With Dividends Yielding More Than 3%</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-06</td>\n",
       "      <td>09:12AM</td>\n",
       "      <td>30 Dividend Kings 2021 Part III</td>\n",
       "      <td>Insider Monkey</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-06</td>\n",
       "      <td>07:30AM</td>\n",
       "      <td>3M, Yum Brands, Other Companies That Raised Th...</td>\n",
       "      <td>Barrons.com</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date     time  \\\n",
       "0    MMM  2021-02-12  05:12PM   \n",
       "1    MMM  2021-02-12  10:10AM   \n",
       "2    MMM  2021-02-12  07:45AM   \n",
       "3    MMM  2021-02-10  06:00AM   \n",
       "4    MMM  2021-02-09  02:35PM   \n",
       "5    MMM  2021-02-09  11:07AM   \n",
       "6    MMM  2021-02-09  11:07AM   \n",
       "7    MMM  2021-02-08  10:30AM   \n",
       "8    MMM  2021-02-06  09:12AM   \n",
       "9    MMM  2021-02-06  07:30AM   \n",
       "\n",
       "                                            headline             news    neg  \\\n",
       "0      First Eagle Investments Top 4thQuarter Trades    GuruFocus.com  0.000   \n",
       "1                     Why 3M Is Retirees Dream Stock      Motley Fool  0.000   \n",
       "2                   3 Top Value Stocks Buy Right Now      Motley Fool  0.000   \n",
       "3  How 19B Bond Fund Finds Opportunity Market Tur...      Barrons.com  0.221   \n",
       "4              3M Announces Upcoming Investor Events      PR Newswire  0.000   \n",
       "5  New 3M Polisher ST reduces number biopharma ma...      PR Newswire  0.000   \n",
       "6  New 3M Polisher ST reduces number biopharma ma...        CNW Group  0.000   \n",
       "7  3 Stocks Buy With Dividends Yielding More Than 3%      Motley Fool  0.000   \n",
       "8                    30 Dividend Kings 2021 Part III   Insider Monkey  0.000   \n",
       "9  3M, Yum Brands, Other Companies That Raised Th...      Barrons.com  0.000   \n",
       "\n",
       "     neu    pos  compound  \n",
       "0  0.735  0.265    0.2023  \n",
       "1  0.714  0.286    0.2500  \n",
       "2  0.488  0.512    0.4939  \n",
       "3  0.531  0.248    0.0772  \n",
       "4  1.000  0.000    0.0000  \n",
       "5  0.874  0.126    0.0772  \n",
       "6  0.874  0.126    0.0772  \n",
       "7  1.000  0.000    0.0000  \n",
       "8  1.000  0.000    0.0000  \n",
       "9  1.000  0.000    0.0000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK VADER for sentiment analysis (unstem)\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Instantiate the sentiment intensity analyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Iterate through the headlines and get the polarity scores using vader\n",
    "scores = parsed_news_updated['headline'].apply(vader.polarity_scores).tolist()\n",
    "\n",
    "# Convert the 'scores' list of dicts into a DataFrame\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "# Join the DataFrames of the news and the list of dicts\n",
    "parsed_and_scored_news = parsed_news_updated.join(scores_df, rsuffix='_right')\n",
    "\n",
    "# Convert the date column from string to datetime\n",
    "parsed_and_scored_news['date'] = pd.to_datetime(parsed_and_scored_news.date).dt.date\n",
    "\n",
    "parsed_and_scored_news.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>headline</th>\n",
       "      <th>news</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>05:12PM</td>\n",
       "      <td>first eagl invest top 4thquarter trade</td>\n",
       "      <td>GuruFocus.com</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>10:10AM</td>\n",
       "      <td>whi 3m retire dream stock</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>07:45AM</td>\n",
       "      <td>3 top valu stock buy right</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>06:00AM</td>\n",
       "      <td>19b bond fund find opportun market turmoil</td>\n",
       "      <td>Barrons.com</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>02:35PM</td>\n",
       "      <td>3m announc upcom investor event</td>\n",
       "      <td>PR Newswire</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>11:07AM</td>\n",
       "      <td>new 3m polish st reduc number biopharma manufa...</td>\n",
       "      <td>PR Newswire</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>11:07AM</td>\n",
       "      <td>new 3m polish st reduc number biopharma manufa...</td>\n",
       "      <td>CNW Group</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>10:30AM</td>\n",
       "      <td>3 stock buy dividend yield 3%</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-06</td>\n",
       "      <td>09:12AM</td>\n",
       "      <td>30 dividend king 2021 part iii</td>\n",
       "      <td>Insider Monkey</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2021-02-06</td>\n",
       "      <td>07:30AM</td>\n",
       "      <td>3m, yum brands, compani rais dividend thi week</td>\n",
       "      <td>Barrons.com</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date     time  \\\n",
       "0    MMM  2021-02-12  05:12PM   \n",
       "1    MMM  2021-02-12  10:10AM   \n",
       "2    MMM  2021-02-12  07:45AM   \n",
       "3    MMM  2021-02-10  06:00AM   \n",
       "4    MMM  2021-02-09  02:35PM   \n",
       "5    MMM  2021-02-09  11:07AM   \n",
       "6    MMM  2021-02-09  11:07AM   \n",
       "7    MMM  2021-02-08  10:30AM   \n",
       "8    MMM  2021-02-06  09:12AM   \n",
       "9    MMM  2021-02-06  07:30AM   \n",
       "\n",
       "                                            headline             news    neg  \\\n",
       "0             first eagl invest top 4thquarter trade    GuruFocus.com  0.000   \n",
       "1                          whi 3m retire dream stock      Motley Fool  0.000   \n",
       "2                         3 top valu stock buy right      Motley Fool  0.000   \n",
       "3         19b bond fund find opportun market turmoil      Barrons.com  0.294   \n",
       "4                    3m announc upcom investor event      PR Newswire  0.000   \n",
       "5  new 3m polish st reduc number biopharma manufa...      PR Newswire  0.000   \n",
       "6  new 3m polish st reduc number biopharma manufa...        CNW Group  0.000   \n",
       "7                      3 stock buy dividend yield 3%      Motley Fool  0.000   \n",
       "8                     30 dividend king 2021 part iii   Insider Monkey  0.000   \n",
       "9     3m, yum brands, compani rais dividend thi week      Barrons.com  0.000   \n",
       "\n",
       "     neu    pos  compound  \n",
       "0  0.735  0.265    0.2023  \n",
       "1  0.667  0.333    0.2500  \n",
       "2  0.690  0.310    0.2023  \n",
       "3  0.706  0.000   -0.3612  \n",
       "4  1.000  0.000    0.0000  \n",
       "5  0.874  0.126    0.0772  \n",
       "6  0.874  0.126    0.0772  \n",
       "7  1.000  0.000    0.0000  \n",
       "8  1.000  0.000    0.0000  \n",
       "9  1.000  0.000    0.0000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK VADER for sentiment analysis (stem)\n",
    "\n",
    "# Instantiate the sentiment intensity analyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Iterate through the headlines and get the polarity scores using vader\n",
    "scores_stem = parsed_news_updated_stem['headline'].apply(vader.polarity_scores).tolist()\n",
    "\n",
    "# Convert the 'scores' list of dicts into a DataFrame\n",
    "scores_stem_df = pd.DataFrame(scores_stem)\n",
    "\n",
    "# Join the DataFrames of the news and the list of dicts\n",
    "parsed_and_scored_news_stem = parsed_news_updated_stem.join(scores_stem_df, rsuffix='_right')\n",
    "\n",
    "# Convert the date column from string to datetime\n",
    "parsed_and_scored_news_stem['date'] = pd.to_datetime(parsed_and_scored_news_stem.date).dt.date\n",
    "\n",
    "parsed_and_scored_news_stem.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:35:12.704918Z",
     "start_time": "2021-02-13T02:35:12.633876Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>1829.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-02</td>\n",
       "      <td>1864.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>1895.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-17</td>\n",
       "      <td>1926.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-18</td>\n",
       "      <td>1917.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    price\n",
       "0 2016-11-02  1829.08\n",
       "1 2016-12-02  1864.78\n",
       "2 2016-02-16  1895.58\n",
       "3 2016-02-17  1926.82\n",
       "4 2016-02-18  1917.83"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get S&P 500 prices\n",
    "# source: https://www.spglobal.com/spdji/en/indices/equity/sp-500/#overview\n",
    "\n",
    "df_sp = pd.read_csv('data/S&P500_5years.csv', usecols=[0,1]) # Use only first 2 columns\n",
    "df_sp.columns = ['date', 'price']\n",
    "df_sp['date'] = pd.to_datetime(df_sp['date'])\n",
    "df_sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:36:17.050503Z",
     "start_time": "2021-02-13T02:35:14.178417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Get a list of 505 stocks from S&P 500\\nsp500 = sandp_df['Symbol'].unique()\\nstart = parsed_and_scored_news['date'].min()\\nend = parsed_and_scored_news['date'].max()\\n\\n# Iterate through each stock to get price\\ndf_stock = pd.DataFrame()\\n\\nfor ticker in sp500:\\n    data = get_stock_price(ticker, start, end)\\n    data['ticker'] = ticker \\n    df_stock = pd.concat([df_stock, data], axis=0)\\n    \\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get S&P 500 individual stock prices\n",
    "\n",
    "# Create a function to get stock price given a ticker \n",
    "def get_stock_price(ticker, start, end):\n",
    "    '''Get prices of a stock in a given period.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): ticker of a company \n",
    "        start (str): date in format of 'YYYY-MM-DD'\n",
    "        end (str): date in format of 'YYYY-MM-DD'\n",
    "    \n",
    "    Returns:\n",
    "        A DataFrame containing open, high, low, close, volume, dividends, stock splits\n",
    "    '''\n",
    "    import yfinance as yf\n",
    "    \n",
    "    ticker = yf.Ticker(ticker)\n",
    "    data = ticker.history(start=start, end=end)\n",
    "    data.reset_index(level=0, inplace=True)\n",
    "    return data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to generate merged dataframe (merged by date)\n",
    "# columns: ['ticker', 'date', 'time', 'headline', 'news', 'neg', 'neu', 'pos', 'compound', 'open', 'close', 'change']\n",
    "# scored dataframe should be the input (not sure if works for scored sentiment other than Vader)\n",
    "\n",
    "\n",
    "def generate_final_df(scored_df):\n",
    "    # Get a list of 505 stocks from S&P 500\n",
    "    sp500 = sandp_df['Symbol'].unique()\n",
    "    start = scored_df['date'].min()\n",
    "    end = scored_df['date'].max()\n",
    "    \n",
    "    # Iterate through each stock to get price\n",
    "    df_stock = pd.DataFrame()\n",
    "    for ticker in sp500:\n",
    "        data = get_stock_price(ticker, start, end)\n",
    "        data['ticker'] = ticker\n",
    "        df_stock = pd.concat([df_stock, data], axis=0)\n",
    "        \n",
    "    # Change all columns names to lowercase  \n",
    "    df_stock.columns = df_stock.columns.str.lower()\n",
    "    \n",
    "    # Convert timestamp to date\n",
    "    df_stock['date'] = df_stock['date'].apply(datetime.date)\n",
    "    \n",
    "    # Reset index\n",
    "    df_stock.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Merge stock price info and sentiment scores\n",
    "    df_merged = scored_df.merge(df_stock.loc[:, ['date', 'ticker', 'open', 'close']], on=['date', 'ticker'])\n",
    "    # Add column: price change\n",
    "    df_merged['change'] = df_merged['close'] - df_merged['open']\n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- BRK.B: No data found, symbol may be delisted\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "# Generate final df for unstem and stem\n",
    "\n",
    "df_final_unstem = generate_final_df(parsed_and_scored_news)\n",
    "df_final_stem = generate_final_df(parsed_and_scored_news_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:37:43.967232Z",
     "start_time": "2021-02-13T02:37:43.917201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news\n",
       " Zacks Small Cap Research           1.000000\n",
       " Skift                              1.000000\n",
       " The Telegraph                      1.000000\n",
       " ETF.com                            1.000000\n",
       " CorpGov.com                        0.745148\n",
       "                                      ...   \n",
       " Exec Edge                               NaN\n",
       " GOBankingRates                          NaN\n",
       " Market Exclusive                        NaN\n",
       " Schaeffer's Investment Research         NaN\n",
       "[email protected]                        NaN\n",
       "Name: (compound, change), Length: 66, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate pearson correlation coef between sentiment score and price for each news media\n",
    "scores_close_unstem = df_final_unstem.groupby('news')[['compound', 'close']].corr().unstack().iloc[:, 1].sort_values(ascending=False)\n",
    "scores_close_stem = df_final_stem.groupby('news')[['compound', 'close']].corr().unstack().iloc[:, 1].sort_values(ascending=False)\n",
    "scores_change_unstem = df_final_unstem.groupby('news')[['compound', 'change']].corr().unstack().iloc[:, 1].sort_values(ascending=False)\n",
    "scores_change_stem = df_final_stem.groupby('news')[['compound', 'change']].corr().unstack().iloc[:, 1].sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/28988627/pandas-correlation-groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate spearman correlation coef between sentiment score and price for each news media\n",
    "scores_close_unstem = df_final_unstem.groupby('news')[['compound', 'close']].corr(method='spearman').unstack().iloc[:, 1].sort_values(ascending=False)\n",
    "scores_close_stem = df_final_stem.groupby('news')[['compound', 'close']].corr(method='spearman').unstack().iloc[:, 1].sort_values(ascending=False)\n",
    "scores_change_unstem = df_final_unstem.groupby('news')[['compound', 'change']].corr(method='spearman').unstack().iloc[:, 1].sort_values(ascending=False)\n",
    "scores_change_stem = df_final_stem.groupby('news')[['compound', 'change']].corr(method='spearman').unstack().iloc[:, 1].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>unstem</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>change</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.011299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>close</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.018769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variable    unstem      stem\n",
       "0   change  0.008800  0.011299\n",
       "1    close -0.000116  0.018769"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pearson's Correlation Coefficient as Dataframe\n",
    "pearson_corr = pd.DataFrame({'variable' : ['close', 'change'], 'unstem' : [df_final_unstem[['compound', 'close']].corr().iloc[0,1], df_final_unstem[['compound', 'change']].corr().iloc[0,1]], 'stem' : [df_final_stem[['compound', 'close']].corr().iloc[0,1], df_final_stem[['compound', 'change']].corr().iloc[0,1]]})\n",
    "pearson_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>unstem</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>change</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.014860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>close</td>\n",
       "      <td>0.026481</td>\n",
       "      <td>0.049613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variable    unstem      stem\n",
       "0   change  0.015127  0.014860\n",
       "1    close  0.026481  0.049613"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spearman's rank correlation\n",
    "spearman_corr = pd.DataFrame({'variable' : ['close', 'change'], 'unstem' : [df_final_unstem[['compound', 'close']].corr(method='spearman').iloc[0,1], df_final_unstem[['compound', 'change']].corr(method='spearman').iloc[0,1]], 'stem' : [df_final_stem[['compound', 'close']].corr(method='spearman').iloc[0,1], df_final_stem[['compound', 'change']].corr(method='spearman').iloc[0,1]]})\n",
    "spearman_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vader Sentiment Analysis\n",
    "\n",
    "Performed Pearson's Correlation Coefficient comparisons between compound sentiment and (1) closing price (2) change in price (closing price - opening price). Computed the Spearman rank correlation coefficient as well.\n",
    "\n",
    "Compared effect of stemming and not stemming words on Pearson's and Spearman's correlation coefficient.\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Pearson:\n",
    "Correlation between both (1) and (2) is negligible (<1%) without stemming. Stemming appears to improve correlation, but correlation is still very small (<2%)\n",
    "\n",
    "Spearman:\n",
    "Correlation for both (1) and (2) is still small, but better than Pearson. Stemming has inconsistent results, slightly lowering (2) but increasing (1)\n",
    "\n",
    "Overall, Vader sentiment analysis produces very weak correlation with both (1) and (2). Try with other models.\n",
    "\n",
    "\n",
    "Note: \n",
    "\n",
    "1. Try removing headlines from less common news sources (eg. headline count < 10). Unlikely to produce significant changes.\n",
    "\n",
    "2. Might be helpful to determine the most relevant news sources by taking highly correlated news sources with instances of more than 20. Limiting the data might increase correlation. Use test set to evaluate if using this method.\n",
    "\n",
    "3. Doing linear regression on neg, neu and pos score might produce interesting results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:38:23.792228Z",
     "start_time": "2021-02-13T02:38:23.778225Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>headline</th>\n",
       "      <th>news</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11629</th>\n",
       "      <td>COST</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>01:14PM</td>\n",
       "      <td>Tesco Britains worst minimum wage offender, BE...</td>\n",
       "      <td>The Telegraph</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>373.462590</td>\n",
       "      <td>373.712097</td>\n",
       "      <td>0.249507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29538</th>\n",
       "      <td>MDLZ</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>06:57AM</td>\n",
       "      <td>Cadbury brings Dairy Milk production back Bour...</td>\n",
       "      <td>The Telegraph</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>55.310001</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.689999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker        date     time  \\\n",
       "11629   COST  2020-12-30  01:14PM   \n",
       "29538   MDLZ  2021-02-04  06:57AM   \n",
       "\n",
       "                                                headline            news  \\\n",
       "11629  Tesco Britains worst minimum wage offender, BE...   The Telegraph   \n",
       "29538  Cadbury brings Dairy Milk production back Bour...   The Telegraph   \n",
       "\n",
       "         neg    neu  pos  compound        open       close    change  \n",
       "11629  0.524  0.476  0.0    -0.765  373.462590  373.712097  0.249507  \n",
       "29538  0.000  1.000  0.0     0.000   55.310001   56.000000  0.689999  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_unstem.loc[df_final_unstem['news']==' The Telegraph', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. Take note of changes in the composition of S&P 500."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
